# backend/app/api/chat.py (Enhanced for RAG with Page Navigation)
from fastapi import APIRouter, HTTPException
from app.models.schemas import ChatRequest, ChatResponse
from app.services.document_processor import vector_collection
from app.services.vectorizer import get_embeddings
from app.services.supabase_client import supabase
from app.services.pdf_service import find_text_locations, create_highlighted_pdf, create_rag_response_with_pages
import openai
import time
import os
import tempfile
from typing import List, Dict, Any
import traceback

router = APIRouter()


@router.post("/chat", response_model=ChatResponse)
async def chat_with_documents(request: ChatRequest):
    """
    ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ (í˜ì´ì§€ ìœ„ì¹˜ ì •ë³´ í¬í•¨)
    """
    start_time = time.time()

    try:
        # 1. ì‚¬ìš©ì ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding = get_embeddings([request.message])[0]

        # 2. ìœ ì‚¬í•œ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰
        search_kwargs = {
            "query_embeddings": [query_embedding],
            "n_results": request.max_results
        }

        # íŠ¹ì • ë¬¸ì„œì—ì„œë§Œ ê²€ìƒ‰í•˜ëŠ” ê²½ìš°
        if request.document_ids:
            search_kwargs["where"] = {
                "document_id": {"$in": request.document_ids}
            }

        search_results = vector_collection.query(**search_kwargs)

        if not search_results["documents"] or not search_results["documents"][0]:
            return ChatResponse(
                status="success",
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
                sources=[],
                document_ids=[],
                processing_time=time.time() - start_time
            )

        # 3. ê²€ìƒ‰ëœ ì²­í¬ë“¤ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        documents = search_results["documents"][0]
        metadatas = search_results["metadatas"][0]
        distances = search_results["distances"][0]

        context_chunks = []
        sources = []
        document_ids = set()

        for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):
            if distance < 0.8:  # ìœ ì‚¬ë„ ì„ê³„ê°’
                context_chunks.append(doc)
                document_ids.add(metadata.get("document_id", ""))

                # ì²­í¬ì—ì„œ í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
                chunk_index = metadata.get("chunk_index", i)

                # ë¬¸ì„œ ì •ë³´ ì¡°íšŒí•´ì„œ ì‹¤ì œ PDF ê²½ë¡œ ì–»ê¸°
                doc_info = await get_document_info(metadata.get("document_id", ""))

                source_info = {
                    "document_id": metadata.get("document_id", ""),
                    "filename": metadata.get("filename", "Unknown"),
                    "chunk_index": chunk_index,
                    "relevance_score": 1 - distance,
                    "content_preview": doc[:200] + "..." if len(doc) > 200 else doc,
                    "full_content": doc,
                    # í˜ì´ì§€ ì •ë³´ (ì‹¤ì œ PDFì—ì„œ ì°¾ì•„ì•¼ í•¨)
                    "page_number": await find_chunk_page_number(doc_info, doc),
                    "bbox": None,  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” PDFì—ì„œ ìœ„ì¹˜ ì°¾ê¸°
                }

                sources.append(source_info)

        if not context_chunks:
            return ChatResponse(
                status="success",
                answer="ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ì˜ ìœ ì‚¬ë„ê°€ ë‚®ì•„ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.",
                sources=[],
                document_ids=[],
                processing_time=time.time() - start_time
            )

        # 4. OpenAI APIë¡œ ë‹µë³€ ìƒì„±
        context = "\n\n".join(context_chunks[:3])

        system_prompt = """ë‹¹ì‹ ì€ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
3. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
4. ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ì„¸ìš”
5. í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš° ê·¸ë ‡ë‹¤ê³  ëª…ì‹œí•˜ì„¸ìš”"""

        user_prompt = f"""ë¬¸ì„œ ë‚´ìš©:
{context}

ì§ˆë¬¸: {request.message}

ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""

        try:
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=1000
            )

            answer = response.choices[0].message.content

        except Exception as openai_error:
            print(f"âŒ OpenAI API ì˜¤ë¥˜: {openai_error}")
            # OpenAI API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë‹µë³€
            answer = f"ë¬¸ì„œì—ì„œ ë‹¤ìŒê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n{context[:500]}...\n\në” êµ¬ì²´ì ì¸ ë‹µë³€ì„ ìœ„í•´ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì •ë¦¬í•´ ì£¼ì„¸ìš”."

        processing_time = time.time() - start_time

        return ChatResponse(
            status="success",
            answer=answer,
            sources=sources,
            document_ids=list(document_ids),
            processing_time=processing_time
        )

    except Exception as e:
        print(f"âŒ ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


async def get_document_info(document_id: str) -> Dict:
    """ë¬¸ì„œ ì •ë³´ ì¡°íšŒ"""
    try:
        response = supabase.from_('documents').select('*').eq('id', document_id).execute()
        if response.data:
            return response.data[0]
        return {}
    except Exception as e:
        print(f"ë¬¸ì„œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {}


async def find_chunk_page_number(doc_info: Dict, chunk_text: str) -> int:
    """ì²­í¬ê°€ ìœ„ì¹˜í•œ í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸°"""
    try:
        if not doc_info.get('url'):
            return 1

        # PDF ë‹¤ìš´ë¡œë“œ (ì„ì‹œ)
        import requests
        response = requests.get(doc_info['url'])

        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
            tmp_file.write(response.content)
            tmp_file_path = tmp_file.name

        try:
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
            locations = find_text_locations(tmp_file_path, chunk_text[:100])
            if locations:
                return locations[0].page_number
            return 1
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_file_path):
                os.remove(tmp_file_path)

    except Exception as e:
        print(f"í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸° ì‹¤íŒ¨: {e}")
        return 1


@router.post("/chat/highlight")
async def create_highlighted_response(
        document_id: str,
        page_number: int,
        search_text: str
):
    """
    íŠ¹ì • í…ìŠ¤íŠ¸ë¥¼ í•˜ì´ë¼ì´íŠ¸í•œ PDF ìƒì„±
    """
    try:
        # ë¬¸ì„œ ì •ë³´ ì¡°íšŒ
        doc_info = await get_document_info(document_id)
        if not doc_info.get('url'):
            raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # PDF ë‹¤ìš´ë¡œë“œ
        import requests
        response = requests.get(doc_info['url'])

        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
            tmp_file.write(response.content)
            tmp_file_path = tmp_file.name

        try:
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
            locations = find_text_locations(tmp_file_path, search_text)

            if not locations:
                return {
                    "status": "error",
                    "message": "í•´ë‹¹ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }

            # í•˜ì´ë¼ì´íŠ¸ëœ PDF ìƒì„±
            highlighted_path = create_highlighted_pdf(tmp_file_path, locations)

            # í•˜ì´ë¼ì´íŠ¸ëœ PDFë¥¼ Supabase Storageì— ì—…ë¡œë“œ
            highlighted_url = await upload_highlighted_pdf(highlighted_path, document_id)

            return {
                "status": "success",
                "highlighted_pdf_url": highlighted_url,
                "page_number": locations[0].page_number,
                "bbox": locations[0].bbox,
                "total_highlights": len(locations)
            }

        finally:
            # ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
            for file_path in [tmp_file_path, highlighted_path]:
                if os.path.exists(file_path):
                    os.remove(file_path)

    except Exception as e:
        print(f"âŒ í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


async def upload_highlighted_pdf(file_path: str, document_id: str) -> str:
    """í•˜ì´ë¼ì´íŠ¸ëœ PDFë¥¼ Supabase Storageì— ì—…ë¡œë“œ"""
    try:
        highlighted_filename = f"highlighted_{document_id}.pdf"

        with open(file_path, 'rb') as f:
            file_content = f.read()

        # Supabase Storageì— ì—…ë¡œë“œ
        upload_response = supabase.storage.from_("pdf-documents").upload(
            path=f"highlighted/{highlighted_filename}",
            file=file_content,
            file_options={"content-type": "application/pdf"}
        )

        # ê³µê°œ URL ìƒì„±
        public_url = supabase.storage.from_("pdf-documents").get_public_url(
            f"highlighted/{highlighted_filename}"
        )

        return public_url

    except Exception as e:
        print(f"í•˜ì´ë¼ì´íŠ¸ëœ PDF ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return ""


@router.get("/chat/page-navigation/{document_id}")
async def get_page_navigation_info(document_id: str, search_text: str):
    """
    íŠ¹ì • í…ìŠ¤íŠ¸ì˜ í˜ì´ì§€ ìœ„ì¹˜ ì •ë³´ ë°˜í™˜ (PDF ë·°ì–´ìš©)
    """
    try:
        # ë¬¸ì„œ ì •ë³´ ì¡°íšŒ
        doc_info = await get_document_info(document_id)
        if not doc_info.get('url'):
            raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # PDF ë‹¤ìš´ë¡œë“œ
        import requests
        response = requests.get(doc_info['url'])

        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
            tmp_file.write(response.content)
            tmp_file_path = tmp_file.name

        try:
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
            locations = find_text_locations(tmp_file_path, search_text)

            navigation_info = []
            for location in locations:
                navigation_info.append({
                    "page_number": location.page_number,
                    "bbox": {
                        "x0": location.bbox[0],
                        "y0": location.bbox[1],
                        "x1": location.bbox[2],
                        "y1": location.bbox[3]
                    },
                    "context": location.context,
                    "matched_text": location.text
                })

            return {
                "status": "success",
                "document_id": document_id,
                "search_text": search_text,
                "total_matches": len(navigation_info),
                "locations": navigation_info,
                "primary_page": navigation_info[0]["page_number"] if navigation_info else 1
            }

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(tmp_file_path):
                os.remove(tmp_file_path)

    except Exception as e:
        print(f"âŒ í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ì •ë³´ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/chat/search")
async def search_documents(query: str, document_ids: List[str] = None, limit: int = 10):
    """
    ë¬¸ì„œ ê²€ìƒ‰ (ë‹µë³€ ìƒì„± ì—†ì´ ê²€ìƒ‰ë§Œ, í˜ì´ì§€ ì •ë³´ í¬í•¨)
    """
    try:
        # ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding = get_embeddings([query])[0]

        # ê²€ìƒ‰ ì‹¤í–‰
        search_kwargs = {
            "query_embeddings": [query_embedding],
            "n_results": limit
        }

        if document_ids:
            search_kwargs["where"] = {
                "document_id": {"$in": document_ids}
            }

        search_results = vector_collection.query(**search_kwargs)

        if not search_results["documents"] or not search_results["documents"][0]:
            return {
                "status": "success",
                "results": [],
                "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            }

        # ê²°ê³¼ ì •ë¦¬ (í˜ì´ì§€ ì •ë³´ í¬í•¨)
        documents = search_results["documents"][0]
        metadatas = search_results["metadatas"][0]
        distances = search_results["distances"][0]

        results = []
        for doc, metadata, distance in zip(documents, metadatas, distances):
            # ë¬¸ì„œ ì •ë³´ ì¡°íšŒ
            doc_info = await get_document_info(metadata.get("document_id", ""))
            page_number = await find_chunk_page_number(doc_info, doc)

            results.append({
                "document_id": metadata.get("document_id", ""),
                "filename": metadata.get("filename", "Unknown"),
                "chunk_index": metadata.get("chunk_index", 0),
                "content": doc,
                "relevance_score": 1 - distance,
                "distance": distance,
                "page_number": page_number,
                "navigation_info": {
                    "can_highlight": True,
                    "can_navigate": True
                }
            })

        return {
            "status": "success",
            "results": results,
            "count": len(results)
        }

    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/chat/documents")
async def get_available_documents():
    """
    ì±„íŒ…ì— ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ (ì™„ë£Œëœ ë¬¸ì„œë§Œ)
    """
    try:
        response = supabase.from_('documents').select('id, filename, created_at, processed_at').eq('status',
                                                                                                   'completed').order(
            'created_at', desc=True).execute()

        return {
            "status": "success",
            "documents": response.data,
            "count": len(response.data)
        }

    except Exception as e:
        print(f"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/chat/feedback")
async def submit_chat_feedback(
        message: str,
        answer: str,
        rating: int,
        feedback_text: str = None,
        page_navigation_used: bool = False,
        highlight_used: bool = False
):
    """
    ì±„íŒ… ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°± ìˆ˜ì§‘ (í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜/í•˜ì´ë¼ì´íŠ¸ ì‚¬ìš© ì—¬ë¶€ í¬í•¨)
    """
    try:
        feedback_data = {
            "message": message,
            "answer": answer,
            "rating": rating,
            "feedback_text": feedback_text,
            "page_navigation_used": page_navigation_used,
            "highlight_used": highlight_used,
            "timestamp": time.time()
        }

        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ë¡œê·¸ë§Œ ì¶œë ¥ (ì‹¤ì œë¡œëŠ” DBì— ì €ì¥)
        print(f"ğŸ“ ì‚¬ìš©ì í”¼ë“œë°±: {feedback_data}")

        return {
            "status": "success",
            "message": "í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        }

    except Exception as e:
        print(f"âŒ í”¼ë“œë°± ì €ì¥ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))